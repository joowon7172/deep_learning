{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38740106",
   "metadata": {},
   "source": [
    "<h1>a_tensor_initialization<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a862680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\users\\joowo\\anaconda3\\lib\\site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\joowo\\anaconda3\\lib\\site-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5f94fa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  C:\\Users\\joowo\\anaconda3\\python.exe -m pip <command> [options]\n",
      "\n",
      "Commands:\n",
      "  install                     Install packages.\n",
      "  download                    Download packages.\n",
      "  uninstall                   Uninstall packages.\n",
      "  freeze                      Output installed packages in requirements format.\n",
      "  inspect                     Inspect the python environment.\n",
      "  list                        List installed packages.\n",
      "  show                        Show information about installed packages.\n",
      "  check                       Verify installed packages have compatible dependencies.\n",
      "  config                      Manage local and global configuration.\n",
      "  search                      Search PyPI for packages.\n",
      "  cache                       Inspect and manage pip's wheel cache.\n",
      "  index                       Inspect information available from package indexes.\n",
      "  wheel                       Build wheels from your requirements.\n",
      "  hash                        Compute hashes of package archives.\n",
      "  completion                  A helper command used for command completion.\n",
      "  debug                       Show information useful for debugging.\n",
      "  help                        Show help for commands.\n",
      "\n",
      "General Options:\n",
      "  -h, --help                  Show help.\n",
      "  --debug                     Let unhandled exceptions propagate outside the\n",
      "                              main subroutine, instead of logging them to\n",
      "                              stderr.\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\n",
      "                              environment variables and user configuration.\n",
      "  --require-virtualenv        Allow pip to only run in a virtual environment;\n",
      "                              exit with an error otherwise.\n",
      "  --python <python>           Run pip with the specified Python interpreter.\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\n",
      "                              used up to 3 times.\n",
      "  -V, --version               Show version and exit.\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\n",
      "                              used up to 3 times (corresponding to WARNING,\n",
      "                              ERROR, and CRITICAL logging levels).\n",
      "  --log <path>                Path to a verbose appending log.\n",
      "  --no-input                  Disable prompting for input.\n",
      "  --keyring-provider <keyring_provider>\n",
      "                              Enable the credential lookup via the keyring\n",
      "                              library if user input is allowed. Specify which\n",
      "                              mechanism to use [disabled, import, subprocess].\n",
      "                              (default: disabled)\n",
      "  --proxy <proxy>             Specify a proxy in the form\n",
      "                              scheme://[user:passwd@]proxy.server:port.\n",
      "  --retries <retries>         Maximum number of retries each connection should\n",
      "                              attempt (default 5 times).\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\n",
      "  --exists-action <action>    Default action when a path already exists:\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\n",
      "  --trusted-host <hostname>   Mark this host or host:port pair as trusted,\n",
      "                              even though it does not have valid or any HTTPS.\n",
      "  --cert <path>               Path to PEM-encoded CA certificate bundle. If\n",
      "                              provided, overrides the default. See 'SSL\n",
      "                              Certificate Verification' in pip documentation\n",
      "                              for more information.\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\n",
      "                              containing the private key and the certificate\n",
      "                              in PEM format.\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\n",
      "  --no-cache-dir              Disable the cache.\n",
      "  --disable-pip-version-check\n",
      "                              Don't periodically check PyPI to determine\n",
      "                              whether a new version of pip is available for\n",
      "                              download. Implied with --no-index.\n",
      "  --no-color                  Suppress colored output.\n",
      "  --no-python-version-warning\n",
      "                              Silence deprecation warnings for upcoming\n",
      "                              unsupported Pythons.\n",
      "  --use-feature <feature>     Enable new functionality, that may be backward\n",
      "                              incompatible.\n",
      "  --use-deprecated <feature>  Enable deprecated functionality, that will be\n",
      "                              removed in the future.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a6fbf50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\joowo\\anaconda3\\lib\\site-packages (23.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "111f77f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\joowo\\anaconda3\\lib\\site-packages (1.5.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fd66b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\joowo\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2fb11d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\joowo\\anaconda3\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "224062b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\joowo\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from imageio) (1.24.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from imageio) (9.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ea3b7eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphio in c:\\users\\joowo\\anaconda3\\lib\\site-packages (0.9.3)\n",
      "Requirement already satisfied: neo4j>=5.2 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from graphio) (5.12.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from graphio) (2.3.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from neo4j>=5.2->graphio) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from pydantic->graphio) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from pydantic->graphio) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from pydantic->graphio) (4.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9b8d6fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in c:\\users\\joowo\\anaconda3\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: torch in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torchviz) (2.0.1+cu118)\n",
      "Requirement already satisfied: graphviz in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torchviz) (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch->torchviz) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch->torchviz) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch->torchviz) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch->torchviz) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from torch->torchviz) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from jinja2->torch->torchviz) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\joowo\\anaconda3\\lib\\site-packages (from sympy->torch->torchviz) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1d227f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "19ed411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.Tensor([1, 2, 3], device='cpu')\n",
    "print(t1.dtype)   # >>> torch.float32\n",
    "print(t1.device)  # >>> cpu\n",
    "print(t1.requires_grad)  # >>> False\n",
    "print(t1.size())  # torch.Size([3])\n",
    "print(t1.shape)   # torch.Size([3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476b892",
   "metadata": {},
   "source": [
    "**torch.tensor** 는 pytorch 라이브러리에서 사용되는 중요한 개체 중 하나이다. \n",
    "**torch.tensor** 는 다차원 배열인 텐서(tensor)를 생성하는 데 사용된다.\n",
    "\n",
    "- **torch.Tensor** *클래스*를 사용하여 텐서 t1 객체를 생성한다. 이 텐서는 주어진 데이터 [1, 2, 3]를 가지며, CPU(device)에서 생성된다.\n",
    "- **dtype** 속성은 텐서의 데이터 타입을 나타낸다. torch.Tensor 는 torch.FloatTensor와 같으며 int64를 float32로 변환한다.\n",
    "- **device** 속성은 텐서가 어떤 장치에 저장되어 있는지 나타낸다. device=\"cpu\" 라고 나와 있으므로, 이 텐서는 cpu에 할당되어있다.\n",
    "- **requires_grad** 속성은 해당 텐서가 autograd를 사용하여 그라디언트를 추적해야 하는지 여부를 나타낸다. 여기서는 False이므로 그라디언트를 추적하지 않는다.\n",
    "- **size()와 shape**는 텐서의 크기를 나타낸다. size()는 크기를 반환하는 함수이며, shape는 텐서의 크기를 나타내는 튜플이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14d5d657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([1,2,3],device='cpu')\n",
    "print(t2.dtype)\n",
    "print(t2.device)\n",
    "print(t2.requires_grad)\n",
    "print(t2.size())\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647b4c8",
   "metadata": {},
   "source": [
    "- **torch.tensor** *함수*를 사용하여 텐서 t2를 생성함. 마찬가지로 주어진 데이터 [1, 2, 3]를 가지며, CPU(device)에서 생성됩니다.\n",
    "- **dtype** 은 torch.int64로 정수형이다.\n",
    "- **device** 속성은 텐서가 어떤 장치(여기서는 CPU)에 저장되어 있는지 나타낸다.\n",
    "- **requires_grad** 속성은 그라디언트 추적 여부를 나타낸다. 여기서는 False 이다.\n",
    "- **size()와 shape** 는 텐서의 크기를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f5c15",
   "metadata": {},
   "source": [
    "### **torch.Tensor와 torch.tensor의 차이**\n",
    "- **torch.Tensor()** : 클래스(class)\n",
    "    - int 입력시 float로 변환\n",
    "    - torch 데이터 입력시 입력 받은 데이터의 메모리 공간을 사용\n",
    "    - list, numpy 데이터 입력 시 입력 받은 데이터를 복사하여 새롭게 torch.Tensor를 만든 후 사용\n",
    "    \n",
    "<br>\n",
    "    \n",
    "- **torch.tensor()** : 함수(function)\n",
    "    - int 입력시 int 그대로\n",
    "    - 입력 받은 데이터를 새로운 메모리 공간으로 *복사* 후 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ee030ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\n",
    "print(a1.shape, a1.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45160c22",
   "metadata": {},
   "source": [
    "- **torch.tensor(1)** : 0차원 텐서. 스칼라 값을 나타냄\n",
    "- **shape** : 텐서의 크기를 나타냄. a1이 0차원 텐서이므로 shape은 torch.Size([])로 나타내어진다.\n",
    "- **ndim** : 텐서의 차원 수를 나타냄. 0차원 텐서이므로 ndim 은 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bff70036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) 1\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([1])\n",
    "print(a2.shape, a2.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3f202",
   "metadata": {},
   "source": [
    "- **torch.tensor([1])** 은 1차원 텐서로 **shape** 은 torch.Size([1]) 이며, ndim은 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6f2a8baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) 1\n"
     ]
    }
   ],
   "source": [
    "a3 = torch.tensor([1, 2, 3, 4, 5])   \n",
    "print(a3.shape, a3.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7596150",
   "metadata": {},
   "source": [
    "- **torch.tensor([1, 2, 3, 4, 5])** : 1차원 벡터를 나타내는 텐서를 생성. 이 벡터에는 5개의 원소가 존재함.\n",
    "- 이 텐서는 1차원이므로 **shape** 은 torch.Size([5, 1]) 다.\n",
    "- 이 텐서는 1차원이므로 **ndim** 은 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5edefc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])\n",
    "print(a4.shape, a4.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad4669",
   "metadata": {},
   "source": [
    "- **torch.tensor([[1], [2], [3], [4], [5]])** : 5x1인 2차원 텐서로, shape은 torch.Size([5])이며, ndim은 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "34d355e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "a5 = torch.tensor([                 # shape: torch.Size([3, 2]), ndims(=rank): 2\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedcbc4",
   "metadata": {},
   "source": [
    "- 크기가 3x2인 2차원 텐서로, shape는 torch.Size([3, 2])이며, ndim은 2이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "14edd5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 1]) 3\n"
     ]
    }
   ],
   "source": [
    "a6 = torch.tensor([                 # shape: torch.Size([3, 2, 1]), ndims(=rank): 3\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32968b",
   "metadata": {},
   "source": [
    "- 크기가 3x2x1인 3차원 텐서로, shape는 torch.Size([3, 2, 1])이며, ndim은 3이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "38c1af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1]) 4\n"
     ]
    }
   ],
   "source": [
    "a7 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 1]), ndims(=rank): 4\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e095d5b",
   "metadata": {},
   "source": [
    "- 크기가 3x1x2x1인 4차원 텐서로, shape는 torch.Size([3, 1, 2, 1])이며, ndim은 4이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1da88611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3]) 4\n"
     ]
    }
   ],
   "source": [
    "a8 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3]), ndims(=rank): 4\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170e355",
   "metadata": {},
   "source": [
    "- 크기가 3x1x2x3인 4차원 텐서로, shape는 torch.Size([3, 1, 2, 3])이며, ndim은 4이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "62ff31f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9354c4",
   "metadata": {},
   "source": [
    "- 크기가 3x1x2x3x1인 5차원 텐서로, shape는 torch.Size([3, 1, 2, 3, 1])이며, ndim은 5이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "461018cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5]) 2\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([                 # shape: torch.Size([4, 5]), ndims(=rank): 2\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "print(a10.shape, a10.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864949d",
   "metadata": {},
   "source": [
    "- 크기가 4x5인 2차원 텐서로, shape는 torch.Size([4, 5])이며, ndim은 2이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "53480ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 5]) 3\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([                 # shape: torch.Size([4, 1, 5]), ndims(=rank): 3\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "])\n",
    "print(a10.shape, a10.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f888a2",
   "metadata": {},
   "source": [
    "- 크기가 4x1x5인 3차원 텐서로, shape는 torch.Size([4, 1, 5])이며, ndim은 3이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "36c2ce3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 3 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a11 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([                 \u001b[38;5;66;03m# ValueError: expected sequence of length 3 at dim 3 (got 2)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     [[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]]],\n\u001b[0;32m      3\u001b[0m     [[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]]],\n\u001b[0;32m      4\u001b[0m     [[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]]],\n\u001b[0;32m      5\u001b[0m     [[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]]],\n\u001b[0;32m      6\u001b[0m ])\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 3 (got 2)"
     ]
    }
   ],
   "source": [
    "a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb497839",
   "metadata": {},
   "source": [
    "- 이 텐서는 3차원 텐서로 시작하는데, 첫 번째 차원의 하위 요소 중 하나가 길이가 달라 오류(ValueError)가 발생한다. \n",
    "- 이를 해결하려면 a11의 모든 하위 요소가 길이 3인 시퀀스를 가져야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06adb4a4",
   "metadata": {},
   "source": [
    "# b_tensor_initialization_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06baf5",
   "metadata": {},
   "source": [
    "- numpy 는 다차원 배열과 행렬 데이터를 다루는 데 효과적인 도구를 제공하며, 수학적 함수와 라이브러리와 통합하여 데이터 분석 및 과학 연구를 위한 풍부한 기능을 제공 \n",
    "<br>\n",
    "\n",
    "- 많은 숫자 데이터를 하나의 변수에 넣고 관리 할 때 리스트는 속도가 느리고 메모리를 많이 차지하는 단점이 있다. 배열(array)을 사용하면 적은 메모리로 많은 데이터를 빠르게 처리할 수 있다. 배열은 리스트와 비슷하지만 다음과 같은 점에서 다르다.\n",
    "\n",
    "    1. 모든 원소가 같은 자료형이어야 한다.\n",
    "\n",
    "    2. 원소의 갯수를 바꿀 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1, 2, 3]\n",
    "t1 = torch.Tensor(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19dd0d",
   "metadata": {},
   "source": [
    "- torch.Tensor() <- (클래스) 을 사용하여 리스트 l1을 텐서로 변환. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3f95e",
   "metadata": {},
   "source": [
    "- torch.tensor() <- (함수) 을 사용하여 리스트 l2를 텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b194db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e38623",
   "metadata": {},
   "source": [
    "- torch.as_tensor 는 다양한 데이터 유형(리스트, NumPy 배열 등)을 PyTorch 텐서로 변환해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88768289",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1[0] = 100\n",
    "l2[0] = 100\n",
    "l3[0] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba142f",
   "metadata": {},
   "source": [
    "- 각 리스트의 첫 번째 인덱스에 100을 넣어줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0598e4c",
   "metadata": {},
   "source": [
    "- **torch.Tensor()와 torch.tensor()는 텐서를 생성할 때 새로운 복사본을 만들어 원본 데이터와 분리된다.**\n",
    "- 첫 번째 인덱스를 변경하기 전에 생성한 텐서 객체는 *기존 값을 참조하지 않고 별도의 값을 가지므로* t1. t2. t3의 출력값은 처음 선언한 리스트 그대로 출력된다.\n",
    "- *Tensor() 는 int를 입력시 float32의 텐서로 변환* 하므로 텐서의 출력은 tensor([1., 2., 3.]) 가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241120e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c748a19",
   "metadata": {},
   "source": [
    "- 배열을 float32 자료형인 텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317df6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ddfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l4[0] = 100\n",
    "l5[0] = 100\n",
    "l6[0] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa512996",
   "metadata": {},
   "source": [
    "- 각 리스트의 첫 번째 인덱스에 100을 넣어줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6814ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c4c55",
   "metadata": {},
   "source": [
    "- numpy array가 있고, 복사를 방지하려면, torch.as_tensor을 사용해야한다. (또는 torch.from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d9d14",
   "metadata": {},
   "source": [
    "# c_tensor_initialization_constant_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.ones(size=(5,))  # or torch.ones(5)\n",
    "t1_like = torch.ones_like(input=t1)\n",
    "print(t1)  # >>> tensor([1., 1., 1., 1., 1.])\n",
    "print(t1_like)  # >>> tensor([1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa5bfd",
   "metadata": {},
   "source": [
    "- torch.ones(size=(5,)) : 크기가 5인 1. 으로 채워진 1차원 텐서를 생성\n",
    "- torch.ones_like(input=t1) : 입력 텐서 t1과 동일한 크기 및 데이터 타입을 가지며 모든 요소가 1. 로 초기화된 새로운 텐서를 생성하는 PyTorch 함수\n",
    "\n",
    "<br>\n",
    "\n",
    "- ones 함수 안에 임의의 정수 a를 넣든 (a)로 넣든 상관 없음. like가 붙은 함수 안에는 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.zeros(size=(6,))  # or torch.zeros(6)\n",
    "t2_like = torch.zeros_like(input=t2)\n",
    "print(t2)  # >>> tensor([0., 0., 0., 0., 0., 0.])\n",
    "print(t2_like)  # >>> tensor([0., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3e9fd",
   "metadata": {},
   "source": [
    "- torch.zeros(size=(6,)) : 크기가 6인 0. 으로 채워진 1차원 텐서를 생성\n",
    "- torch.zeros_like(input=t1) : 입력 텐서 t1과 동일한 크기 및 데이터 타입을 가지며 모든 요소가 0. 로 초기화된 새로운 텐서를 생성하는 PyTorch 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.empty(size=(4,))  # or torch.zeros(4)\n",
    "t3_like = torch.empty_like(input=t3)\n",
    "print(t3)  # 메모리의 임의의 값\n",
    "print(t3_like)  # 메모리의 임의의 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de09122",
   "metadata": {},
   "source": [
    "- torch.empty() 는 초기화 되지 않은 텐서를 생성한다. 그래서 텐서의 값은 이전에 메모리에 있던 임의의 값일 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df66a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = torch.eye(n=3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f977cb0",
   "metadata": {},
   "source": [
    "- torch.eye(n=3) : 크기가 3x3인 단위행렬 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af862138",
   "metadata": {},
   "source": [
    "# d_tensor_initialization_random_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29088ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randint(low=10, high=20, size=(1, 2))\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d94eec",
   "metadata": {},
   "source": [
    "- torch.randint() 함수를 호출하여 랜덤한 정수를 생성\n",
    "- low 매개변수는 생성할 정수의 최소값을 나타냄. low 이상\n",
    "- high 매개변수는 생성할 정수의 최대값을 나타냄. high 미만\n",
    "- size 매개변수는 생성할 텐서의 크기를 지정. 따라서 1x2 크기의 텐서를 생성.\n",
    "- 결과적으로 t1은 1x2 크기의 텐서이며, 범위가 10에서 19 사이의 랜덤한 정수로 채워져 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.rand(size=(1, 3))\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2492c124",
   "metadata": {},
   "source": [
    "- torch.rand(size=(1,3)) : 크기가 1x3인 균등분포에서 0에서 1사이의 float 값을 가지는 랜덤한 숫자로 채워진 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc36134",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.randn(size=(1, 3))\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b9785",
   "metadata": {},
   "source": [
    "- torch.randn(size=(1, 3)) : 크기가 1x3인 평균이 0이고 표준편차가 1인 정규분포에서 랜덤한 숫자로 채워진 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f74608",
   "metadata": {},
   "source": [
    "- 평균이 10.0 이고 표준편차가 1.0 , 크기가 3x2인 정규분포에서 랜덤한 숫자로 채워진 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe3cd6",
   "metadata": {},
   "source": [
    "- torch.linspace(start=0.0, end=5.0, steps=3) : 시작값(start)과 끝값(end) 사이에서 일정한 간격으로 선형 공간을 나타내는 텐서를 생성\n",
    "\n",
    "<br>\n",
    "\n",
    "- torch.linspace() 함수를 호출하여 선형 공간을 나타내는 텐서를 생성\n",
    "- start 매개변수는 선형 공간의 시작값을 나타내며, 여기서는 0.0으로 설정됨\n",
    "- end 매개변수는 선형 공간의 끝값을 나타내며, 여기서는 5.0으로 설정됨\n",
    "- steps 매개변수는 생성할 텐서의 길이 또는 단계 수를 나타내며, 생성될 텐서의 요소 수를 나타냄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t6 = torch.arange(5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80418779",
   "metadata": {},
   "source": [
    "- torch.arange() 함수는 기본적으로 0부터 시작(start = 0이 디폴트 값)하여 주어진 범위 내의 정수를 생성함. \n",
    "- 따라서 이 코드는 0부터 4까지의 정수를 생성하여 1차원 텐서로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fe839",
   "metadata": {},
   "source": [
    "- torch.manual_seed() 함수를 사용하여 난수 생성 시드를 설정. \n",
    "- 1729는 임의로 선택한 시드 값임. 시드를 설정하면 같은 시드를 사용하여 난수를 생성할 때마다 항상 같은 난수 값이 출력됨(값 재생산 보장). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e38fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random2 = torch.rand(2, 3)\n",
    "print(random2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd16415",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257195b",
   "metadata": {},
   "source": [
    "- 위에서 이미 1729로 설정한 시드값으로 생성한 난수 텐서가 존재(random1). 그러므로 random3도 random1과 같은 텐서로 생성됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a1991",
   "metadata": {},
   "source": [
    "- 일반적인 rand() 함수를 이용하여 2x3 크기의 0부터 1사이의 난수 텐서 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b81734",
   "metadata": {},
   "source": [
    "# e_tensor_type_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c848c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((2, 3))\n",
    "print(a.dtype)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc95d059",
   "metadata": {},
   "source": [
    "- torch.ones의 데이터 타입은 float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.ones((2, 3), dtype=torch.int16)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a2034",
   "metadata": {},
   "source": [
    "- a의 데이터 타입을 int16으로 지정하고 그것을 b로 하여 출력하면 정수값으로 이루어진 텐서가 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05568dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0a00e",
   "metadata": {},
   "source": [
    "- 생성한 float64형 난수 텐서의 값 하나하나에 20곱한 텐서가 출력됨. 스칼라 값이 난수 텐서에 적용됨(broadcasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d718e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = b.to(torch.int32)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0cdd8",
   "metadata": {},
   "source": [
    "- int16형인 b를 int32형으로 변환한 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca62089",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_d = torch.ones(10, 2, dtype=torch.double)\n",
    "short_e = torch.tensor([[1, 2]], dtype=torch.short)\n",
    "print(double_d)\n",
    "print(short_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b24c97",
   "metadata": {},
   "source": [
    "- double_d는 10x2 크기의 모든 요소가 1이고 데이터 타입이 torch.double인 텐서\n",
    "- short_e는 1x2 크기의 데이터 [1, 2]를 가지며 데이터 타입이 torch.short (또는 torch.int16)인 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468abe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_d = torch.zeros(10, 2).double()\n",
    "short_e = torch.ones(10, 2).short()\n",
    "print(double_d)\n",
    "print(short_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2f89c",
   "metadata": {},
   "source": [
    "- double_d는 10x2 크기의 모든 요소가 0이고 데이터 타입이 torch.double인 텐서로 재할당됨\n",
    "- short_e는 10x2 크기의 모든 요소가 1이고 데이터 타입이 torch.short인 텐서로 재할당됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e447c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_d = torch.zeros(10, 2).to(torch.double)\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short)\n",
    "print(double_d)\n",
    "print(short_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b9e067",
   "metadata": {},
   "source": [
    "#### to() 메서드를 사용하여 데이터 타입을 변경\n",
    "\n",
    "<br>\n",
    "\n",
    "- double_d는 10x2 크기의 모든 요소가 0이고 데이터 타입이 torch.double로 변경됨\n",
    "- short_e는 10x2 크기의 모든 요소가 1이고 데이터 타입이 torch.short로 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_d = torch.zeros(10, 2).type(torch.double)\n",
    "short_e = torch.ones(10, 2). type(dtype=torch.short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ff46b",
   "metadata": {},
   "source": [
    "#### type() 메서드를 사용하여 데이터 타입을 변경\n",
    "\n",
    "<br>\n",
    "\n",
    "- double_d는 10x2 크기의 모든 요소가 0이고 데이터 타입이 torch.double로 변경됨\n",
    "- short_e는 10x2 크기의 모든 요소가 1이고 데이터 타입이 torch.short로 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(double_d.dtype)\n",
    "print(short_e.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_f = torch.rand(5, dtype=torch.double)\n",
    "short_g = double_f.to(torch.short)\n",
    "print(double_f)\n",
    "print(short_g) # short_g 라는 새로운 텐서가 생성됨. 계산에 사용된 double_f 값에는 영향이 없음\n",
    "print((double_f * short_g).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c9a8d",
   "metadata": {},
   "source": [
    "**주의**\n",
    "- 데이터 타입 변경 메서드나 함수를 사용할 때에도 원래의 텐서를 변경하는 것이 아니라, 변경된 새로운 텐서를 반환함. 따라서 각 블록에서 재할당을 해줘야 원하는 데이터 타입을 가진 새로운 텐서를 얻을 수 있음\n",
    "<br>\n",
    "\n",
    "- PyTorch에서 다양한 데이터 타입의 텐서 간 연산을 수행할 때, 연산 결과의 데이터 타입은 두 입력 텐서 중 보다 높은 범위의 데이터 타입으로 결정됨 \n",
    "- 따라서 torch.double은 torch.short보다 더 높은 범위의 데이터 타입이므로 곱셈 연산 결과는 torch.double이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd8ea9",
   "metadata": {},
   "source": [
    "# f_tensor_operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e944c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "t3 = torch.add(t1, t2) # torch.add(input , other) : input + other\n",
    "t4 = t1 + t2\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6efcb",
   "metadata": {},
   "source": [
    "- 생성된 t1, t2 텐서 더하기. torch.add(input + other) 형식\n",
    "- Element-wise operations (원소끼리의 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.sub(t1, t2) # torch.sub(input , other) : input - other\n",
    "t6 = t1 - t2\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = torch.mul(t1, t2) # torch.mul(input , other) : input * other\n",
    "t8 = t1 * t2\n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "t9 = torch.div(t1, t2) # torch.div(input , other) : input / other\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffea68a",
   "metadata": {},
   "source": [
    "# g_tensor_operations_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.dot(\n",
    "  torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2427f6c",
   "metadata": {},
   "source": [
    "- 두 개의 1차원 텐서의 내적(dot product)을 계산\n",
    "- 2x2 + 3x1 = 4+3 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb089289",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.randn(2, 3) #  randn: 평균이 0이고 표준편차가 1인 정규분포에서 랜덤한 숫자로 채워진 텐서를 생성\n",
    "t3 = torch.randn(3, 2)\n",
    "t4 = torch.mm(t2, t3)\n",
    "print(t4, t4.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d6e92",
   "metadata": {},
   "source": [
    "- torch.mm(t2, t3) : 두 행렬인 t2와 t3의 행렬 곱을 계산\n",
    "- n x m, m x p => n x p \n",
    "- broadcasting (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.randn(10, 3, 4)\n",
    "#print(t5)\n",
    "t6 = torch.randn(10, 4, 5)\n",
    "#print(t6)\n",
    "t7 = torch.bmm(t5, t6)\n",
    "print(t7.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf38cf",
   "metadata": {},
   "source": [
    "#### 배치 행렬: 배치 행렬(batched matrix)은 여러 개의 행렬을 하나의 텐서로 표현한 데이터 구조이며, 각 행렬의 크기(shape)가 같아야한다.\n",
    "#### b x n x p , b x m x p => b x n x p  (b는 같아야한다)\n",
    "- torch.randn(10, 3, 4): 10개의 배치가 있는 3x4 크기의 랜덤한 값을 가지는 배치 행렬 t5를 생성\n",
    "- torch.randn(10, 4, 5): 10개의 배치가 있는 4x5 크기의 랜덤한 값을 가지는 배치 행렬 t6를 생성\n",
    "- torch.bmm(t5, t6): t5, t6 배치(batch) 행렬 간 곱셈(batch matrix-matrix multiplication)을 수행\n",
    "<br>\n",
    "\n",
    "- torch.bmm() 함수의 결과는 t5와 t6의 배치 행렬 곱셈 결과로, 새로운 배치 행렬의 크기는 (10, 3, 5)가 된다. 3x4, 4x5 => 3x5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752425c3",
   "metadata": {},
   "source": [
    "# h_tensor_operations_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(3)\n",
    "t2 = torch.randn(3)\n",
    "print(torch.matmul(t1, t2).size())  # torch.Size([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fd414",
   "metadata": {},
   "source": [
    "- matmul(Tensor, Tensor) : 다차원 텐서 곱에 사용됨. broadcasting (O)\n",
    "\n",
    "### torch.matmul() 의 주요 특징\n",
    "\n",
    "- **다양한 입력 유형 지원** : torch.matmul() 함수는 다차원 배열, 행렬, 벡터, 스칼라 등 다양한 입력 유형을 지원한다. 이 함수는 입력에 따라 자동으로 올바른 행렬 곱셈 연산을 수행한다.\n",
    "\n",
    "- **행렬 곱셈** : 두 개의 행렬을 입력으로 받아 행렬 곱셈을 수행합니다. 두 행렬의 차원이 (m x n)과 (n x p)이면 결과 행렬은 (m x p) 차원을 가집니다.\n",
    "\n",
    "- **행렬-벡터 및 벡터-행렬 곱셈** : 행렬과 벡터 간의 곱셈 또는 벡터와 행렬 간의 곱셈도 지원됩니다. 이 때 벡터는 1차원 텐서로 표현됩니다.\n",
    "\n",
    "- **브로드캐스팅** : torch.matmul() 함수는 Broadcasting을 지원하여 입력 텐서의 크기를 자동으로 조정하여 행렬 곱셈을 수행할 수 있습니다.\n",
    "\n",
    "- **자동 형변환** : 입력 텐서의 데이터 형식이 다를 경우 자동으로 형변환을 수행하여 호환되는 데이터 형식으로 연산을 수행합니다.\n",
    "\n",
    "- **배치(batch) 행렬 곱셈** : 배치 처리를 지원하여 여러 개의 배치 행렬 간의 곱셈을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.randn(3, 4)\n",
    "#print(t3)\n",
    "t4 = torch.randn(4)\n",
    "#print(t4)\n",
    "print(torch.matmul(t3, t4).size())  # torch.Size([3])\n",
    "#print(torch.matmul(t3, t4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c113387",
   "metadata": {},
   "source": [
    "- t4는 broadcasting을 통해 t3의 각 행에 대해 독립적으로 곱셈이 수행된다.\n",
    "- t4와의 내적이 계산된 것이므로, 결과는 3개의 요소를 가진 텐서가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77437b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치행렬 x 벡터 => 내적 브로드캐스팅\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "#print(t5)\n",
    "t6 = torch.randn(4)\n",
    "print(torch.matmul(t5, t6).size())  # torch.Size([10, 3])\n",
    "#print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3330466",
   "metadata": {},
   "source": [
    "### Broadcasting 은 텐서가 실제로 변하는 것이 아니다!\n",
    "### Torch의 broadcasting은 텐서를 확장하여 다른 텐서와 호환되도록 만드는 메커니즘이다. \n",
    "### 이것은 실제로 텐서의 데이터를 물리적으로 변경하는 것이 아니라 가상으로 처리되는 것이다. \n",
    "### 즉, 텐서 데이터는 변화하지 않고, 연산 시에만 필요한 부분이 임시로 가상으로 확장된다.\n",
    "\n",
    "\n",
    "### Broadcasting 규칙\n",
    "- 각 텐서는 적어도 하나의 차원을 가져야 한다.\n",
    "- 차원의 수가 다를 때: 두 배열 간의 연산을 수행하려면 두 배열의 차원 수가 같아야 한다. 차원 수가 다를 경우, 더 작은 차원의 배열에 덧붙여 2개의 배열의 차원 수를 일치시킬 수 있다.\n",
    "- 차원의 크기가 다를 때: 차원 수가 같은 경우에도 각 차원의 크기가 다를 경우, 크기가 1인 차원은 다른 배열과 일치하도록 확장된다. 이는 브로드캐스팅의 핵심 규칙 중 하나이다.\n",
    "<br>\n",
    "\n",
    "- t6은 broadcasting 되어 size가 torch.Size([10,1,4]) 가 되어 matmul을 수행하게 된다. **<=** *확장된 텐서의 크기가 저게 맞는지 확실하지 않음*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmm을 활용한 배치 행렬 x 배치 행렬\n",
    "t7 = torch.randn(10, 3, 4)\n",
    "t8 = torch.randn(10, 4, 5)\n",
    "print(torch.matmul(t7, t8).size())  # torch.Size([10, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4726aad",
   "metadata": {},
   "source": [
    "- t7과 t8의 행렬곱셉 수행. 행렬 곱셈을 수행하면 t7의 마지막 차원(4)과 t8의 두 번째 차원(4)이 일치하므로 행렬 곱셈이 가능하다.\n",
    "- 행렬 곱 결과 텐서의 크기는 torch.Size([10, 3, 5]) 가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmm을 활용한 배치 행렬 x 배치 행렬\n",
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4, 5)\n",
    "print(torch.matmul(t9, t10).size())  # torch.Size([10, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a5354b",
   "metadata": {},
   "source": [
    "- t10이 t9와 크기를 맞추기 위해 브로드캐스팅 되며, matmul 한 결과 크기는 torch.Size([10, 3, 5])가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d4556",
   "metadata": {},
   "source": [
    "# i_tensor_broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a572fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9f330",
   "metadata": {},
   "source": [
    "- t2가 broadcasting 되어서 곱 t1과 곱 연산이 실행된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712501b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b86569",
   "metadata": {},
   "source": [
    "- t3은 크기가 [3,2] 이고 t4는 크기가 [1,2] 이다. 뒤의 2는 같으므로 broadcasting 가능하므로, t4 가 broadcasting 되어 빼기 연산이 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t5 + 2.0)  # t5.add(2.0)\n",
    "print(t5 - 2.0)  # t5.sub(2.0)\n",
    "print(t5 * 2.0)  # t5.mul(2.0)\n",
    "print(t5 / 2.0)  # t5.div(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a236ebd",
   "metadata": {},
   "source": [
    "- 2.0은 각 연산에서 broadcasting 되어 연산이 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "  return x / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac6cdf",
   "metadata": {},
   "source": [
    "- 매개변수 x를 255로 나눈 값을 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9badab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t6 = torch.randn(3, 28, 28) # 평균이 0, 표준편차가 1인 표쥰정규분포를 따르는 난수를 생성하는 함수\n",
    "print(normalize(t6).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6db701",
   "metadata": {},
   "source": [
    "- 생성된 난수 텐서에 255를 나누어도 크기는 그대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = torch.tensor([[1, 2], [0, 3]])  # torch.Size([2, 2])\n",
    "t8 = torch.tensor([[3, 1]])  # torch.Size([1, 2])\n",
    "t9 = torch.tensor([[5], [2]])  # torch.Size([2, 1])\n",
    "t10 = torch.tensor([7])  # torch.Size([1])\n",
    "print(t7 + t8)   # >>> tensor([[4, 3], [3, 4]])\n",
    "print(t7 + t9)   # >>> tensor([[6, 7], [2, 5]])\n",
    "print(t8 + t9)   # >>> tensor([[8, 6], [5, 3]])\n",
    "print(t7 + t10)  # >>> tensor([[ 8, 9], [ 7, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19459ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t11 = torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2)  # 3rd & 2nd dims identical to t11, dim 0 absent\n",
    "print(t12.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa11ce5",
   "metadata": {},
   "source": [
    "- 크기가 [4,3,2]인 1로 이루어진 t11  \n",
    "- 0부터 1사이의 난수로 이루어진 크기가 [3,2]인 텐서와 t11과 곱 연산이 이루어지면 broadcasting이 나타나고 연산된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691861ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "t13 = torch.ones(4, 3, 2)\n",
    "t14 = t13 * torch.rand(3, 1)  # 3rd dim = 1, 2nd dim is identical to t13\n",
    "print(t14.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742a5e0",
   "metadata": {},
   "source": [
    "- torch.rand(3, 1) 에서 [3,2]를 만들어주기 위해 broadcasting 되고 이후 [4,3,2]가 되기 위해 broadcasting 된다. 이 broadcasting은 실제가 아니라 모두 가상으로 변하여 계산되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t15 = torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)  # 3rd dim is identical to t15, 2nd dim is 1\n",
    "print(t16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53750e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 = torch.rand(3, 1, 1)  # 2nd dim is identical to t17, 3rd and 4th dims are 1\n",
    "print((t17 + t18).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798de78",
   "metadata": {},
   "source": [
    "- 2번째 요소의 크기가 같기 때문에 broadcasting 하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e49c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size())  # torch.Size([5, 3, 4, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db87ea",
   "metadata": {},
   "source": [
    "- 마지막 요소의 크기가 같기 때문에 broadcasting 하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "t21 = torch.empty(1) # 지정된 크기의 빈(empty) 텐서를 생성한다.\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size())  # torch.Size([3, 1, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t23 = torch.ones(3, 3, 3)\n",
    "t24 = torch.ones(3, 1, 3)\n",
    "print((t23 + t24).size())  # torch.Size([3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t25 = torch.empty(5, 2, 4, 1)\n",
    "t26 = torch.empty(3, 1, 1)\n",
    "print((t25 + t26).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8eafbf",
   "metadata": {},
   "source": [
    "- 차원을 증가시킨 후 동일한 차원과 비교하여 큰 값을 따라갈 수 있는 경우는 연산이 가능\n",
    "- 차원을 따라갈수없는 경우 즉 위의 2->3인 경우는 연산 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839112cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t27 = torch.ones(4) * 5\n",
    "print(t27)  # tensor([ 5, 5, 5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec55b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)  # tensor([ 25, 25, 25, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7863e",
   "metadata": {},
   "source": [
    "- pow(a,b) 함수는 a의 b 제곱을 해주는 함수이다. pow 함수에도 broadcasting이 적용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bcb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = torch.arange(1., 5.)  # tensor([ 1., 2., 3., 4.])\n",
    "a = torch.arange(1., 5.)  # tensor([ 1., 2., 3., 4.])\n",
    "t29 = torch.pow(a, exp)\n",
    "print(t29)  # tensor([1., 4., 27., 256.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388773b8",
   "metadata": {},
   "source": [
    "#### torch.arange(start, end, step=1, dtype=None)의 형식을 가짐\n",
    "\n",
    "- start: 시작 값. \n",
    "- end: 종료 값. 이 값 바로 이전까지 생성됨. 이 값은 결과에 포함되지 않는다.\n",
    "- step: 각 요소 간의 간격을 나타내는 값. 기본값은 1이며, 연속된 정수를 생성할 때 사용된다.\n",
    "- dtype: 생성된 텐서의 데이터 타입을 지정함. 기본값은 None이며, 이 경우에는 데이터 타입이 자동으로 추론된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a1d2e",
   "metadata": {},
   "source": [
    "# j_tensor_indexing_slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e88ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9],\n",
    "   [10, 11, 12, 13, 14]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da24469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 설명은 행과 열을 0번째 부터 시작한다고 가정\n",
    "# ,로 구분된 슬라이싱 범위 중 첫 번째는 행을 나타내고, 두 번째는 열을 나타낸다.\n",
    "print(x[1])  # \n",
    "print(x[:, 1])  # 텐서의 모든 행에 대하여 1 번째 열을 나타냄\n",
    "print(x[1, 2])  # 1 번째 행의 2 번째 요소\n",
    "print(x[:, -1])  # 모든 행에 대하여 마지막 열의 값들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f0b11",
   "metadata": {},
   "source": [
    "- 인덱싱의 여러 표기법을 보여줌. 잘 숙지하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[1:])  # 1 번째 행부터의 모든 요소\n",
    "print(x[1:, 3:])  # 1 번째 행부터 끝까지의 행과 3 번째 열부터 끝까지의 열을 선택하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658efe6a",
   "metadata": {},
   "source": [
    "- ,로 구분된 슬라이싱 범위 중 첫 번째는 행을 나타내고, 두 번째는 열을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66717030",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros((6, 6))\n",
    "y[1:4, 2] = 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ce4be",
   "metadata": {},
   "source": [
    "- y의 1 번째 행 부터 3 번째 행에서의 2 번째 열을 1로 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[1:4, 1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163c27d",
   "metadata": {},
   "source": [
    "- 1 번째 행부터 3 번째 행에서 1 번째 열 부터 3 번째 열 까지를 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85519543",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.tensor(\n",
    "  [[1, 2, 3, 4],\n",
    "   [2, 3, 4, 5],\n",
    "   [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2]) # 0 번째 행 부터 1 번째 행\n",
    "print(z[1:, 1:3]) # 1 번째 행 부터 마지막 행 중에서 1 번째 열 부터 2 번째 열 까지\n",
    "print(z[:, 1:]) # 모든 행에 대하여 1 번째 열 부터의 열을 나타내라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[1:, 1:3] = 0 # 1 번째 행부터 마지막 행에 대하여 1 번째 열 부터 2 번째 열을 0으로 바꿔라\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad6108",
   "metadata": {},
   "source": [
    "# k_tensor_reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bbeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = t1.view(3, 2)  # t1 의 모양을 [3,2] 로 변경한 결과인 텐서 t2\n",
    "t3 = t1.reshape(1, 6)  # t1의 모양을 [1,6]로 변경한 결과인 텐서 t3\n",
    "#print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81262bbc",
   "metadata": {},
   "source": [
    "- t1과 t2는 동일한 데이터를 공유하지만 모양이 다르다\n",
    "- 마찬가지로 t1과 t3는 동일한 데이터를 공유하지만 모양이 다르다.\n",
    "\n",
    "#### 주의해야할 점\n",
    "- .view()와 .reshape()를 사용할 때 모양 변경이 가능한 경우에만 작동함\n",
    "- 원래 데이터의 크기와 새로운 모양의 요소 수가 일치해야 함\n",
    "\n",
    "\n",
    "### view와 reshape 의 차이\n",
    "##### view() 메서드:\n",
    "- view() 메서드는 텐서의 모양을 변경하며, 원래 텐서와 반환된 새 텐서가 같은 데이터를 공유합니다.\n",
    "- view() 메서드는 메모리 복제 없이 모양을 변경할 수 있습니다.\n",
    "- 모양 변경이 가능한 경우에만 작동하며, 새로운 모양의 요소 수가 원래 텐서의 요소 수와 일치해야 합니다.\n",
    "- view() 메서드를 사용할 때 모양 변경이 불가능한 경우 RuntimeError가 발생할 수 있습니다.\n",
    "\n",
    "##### reshape() 메서드:\n",
    "- reshape() 메서드도 텐서의 모양을 변경하며, 원래 텐서와 반환된 새 텐서가 같은 데이터를 공유합니다.\n",
    "- reshape()은 view()와 유사하지만 일부 구현에서는 새로운 메모리를 할당하여 데이터를 복제할 수 있습니다.\n",
    "- 모양 변경이 가능한 경우에만 작동하며, 요소 수가 일치해야 합니다.\n",
    "- reshape() 메서드를 사용할 때 모양 변경이 불가능한 경우 RuntimeError가 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117af06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = torch.arange(8).view(2, 4)  \n",
    "t5 = torch.arange(6).view(2, 3)  \n",
    "print(t4)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e78495",
   "metadata": {},
   "outputs": [],
   "source": [
    "t6 = torch.tensor([[[1], [2], [3]]]) # (1, 3, 1) 모양의 원래 텐서 t6을 생성. 이 텐서는 3차원이며 각 차원의 크기는 (1, 3, 1)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = t6.squeeze() # squeeze() 메서드를 사용하여 t6의 모든 크기가 1인 차원을 제거\n",
    "print(t7)\n",
    "print(t7.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383637f",
   "metadata": {},
   "source": [
    "#### squeeze 함수\n",
    "- squeeze() 함수는 PyTorch에서 텐서의 차원 중 크기가 1인 차원을 제거하는 데 사용되는 함수이다.\n",
    "<br>\n",
    "\n",
    "-  squeeze() 메서드를 사용하여 t6의 모든 크기가 1인 차원을 제거\n",
    "- 결과적으로 t7은 (3,) 모양의 텐서가 됨.  tensor([1, 2, 3])\n",
    "- 결과적으로 크기가 1인 차원이 제거되고 단일 차원 텐서로 축소됨\n",
    "\n",
    "### (3)과 (3,)의 차이\n",
    "\n",
    "- (3)은 숫자 3을 가진 단순한 값이며, 텐서의 모양(크기)을 나타내지 않습니다.\n",
    "- (3,)은 1차원 텐서를 나타내는 튜플로, 해당 차원에 3개의 요소가 있다는 것을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 0 차원이 크기가 1인 경우 제거\n",
    "t8 = t6.squeeze(0)  \n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ace2a3",
   "metadata": {},
   "source": [
    "- squeeze(0)은 0번째 차원(첫 번째 차원)이 크기 1인 경우에만 해당 차원을 제거하라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "t9 = torch.tensor([1, 2, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a225856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsqueeze() : 새로운 차원을 추가\n",
    "t10 = t9.unsqueeze(1)  # unsqueeze(1) 메서드를 사용하여 새로운 차원을 인덱스 1(두 번째 차원)에 추가\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147fd66b",
   "metadata": {},
   "source": [
    "- unsqueeze() : 새로운 차원을 추가\n",
    "- unsqueeze(1) 메서드를 사용하여 새로운 차원을 인덱스 1(두 번째 차원)에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "t11 = torch.tensor(\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1)  # (2,1,3)\n",
    "print(t12, t12.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccba4c8",
   "metadata": {},
   "source": [
    "- t11의 인덱스 1 차원인 [1,2,3],[4,5,6] 바깥에 괄호를 씌워 차원을 생성해준다.\n",
    "- t11의 원래 모양은 (2,3) 이었으나, 생성된 차원 결과 t12는 (2,1,3)가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t13의 원래 모양 : (2,3)\n",
    "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1d961",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten() : 텐서를 플래튼(1차원으로 평탄화)해줌\n",
    "t14 = t13.flatten()  # Shape becomes (6,)\n",
    "print(t14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678a6f9",
   "metadata": {},
   "source": [
    "- t13 의 (2,3) shape에서 flatten을 해주어 (6,)로 만들어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae03fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tensor with shape (2, 2, 2)\n",
    "t15 = torch.tensor([[[1, 2],\n",
    "                     [3, 4]],\n",
    "                    [[5, 6],\n",
    "                     [7, 8]]])\n",
    "t16 = torch.flatten(t15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376651c3",
   "metadata": {},
   "source": [
    "- (2,2,2) 인 3차원을 1차원으로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "t17 = torch.flatten(t15, start_dim=1)\n",
    "\n",
    "print(t16)\n",
    "print(t17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3e0b3",
   "metadata": {},
   "source": [
    "- start_dim이 1이므로 1차원 부터 평탄화를 시작한다.\n",
    "\n",
    "### flatten의 주요 매개변수\n",
    "\n",
    "##### start_dim (int, optional):\n",
    "\n",
    "- 기본값: 0\n",
    "- start_dim 매개변수는 평탄화를 시작할 차원의 인덱스를 지정합니다.\n",
    "- 예를 들어, 다차원 텐서에서 특정 차원 이후부터 평탄화를 수행하려면 start_dim을 설정할 수 있습니다.\n",
    "\n",
    "##### end_dim (int, optional):\n",
    "\n",
    "- 기본값: -1\n",
    "- end_dim 매개변수는 평탄화를 끝낼 차원의 인덱스를 지정합니다.\n",
    "- start_dim과 함께 사용하여 평탄화를 시작과 끝 지점을 정의할 수 있습니다.\n",
    "- 음수 값을 사용하면 텐서의 역방향 차원을 나타냅니다. 따라서 -1은 마지막 차원을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)  # >>> torch.Size([2, 3, 5])\n",
    "print(torch.permute(t18, (2, 0, 1)).size())  # >>> torch.Size([5, 2, 3])\n",
    "#print(t18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5637a2b",
   "metadata": {},
   "source": [
    "### 차원을 재배열하는 함수 permute(input_tensor, dims)\n",
    "\n",
    "- input_tensor: 차원을 재배열할 원본 텐서\n",
    "- dims: 재배열된 차원의 순서를 지정하는 튜플(tuple) 또는 리스트(list)\n",
    "\n",
    "- 여기서 torch.permute(t18, (2, 0, 1))은 t18을 2차원, 0차원, 1차원 순서로 재배열 하라는 의미이다.\n",
    "- 원본 t18은 바뀌지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t19의 shape : (2,3)\n",
    "t20 = torch.permute(t19, dims=(0, 1))  # (2,3)\n",
    "t21 = torch.permute(t19, dims=(1, 0))  # (3,2)\n",
    "print(t20)\n",
    "print(t21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56caa223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose : 텐서를 전치하는 과정을 수행\n",
    "t22 = torch.transpose(t19, 0, 1)  # (3,2)\n",
    "print(t22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5407418",
   "metadata": {},
   "source": [
    "- transpose(t19, 0, 1) : t19 텐서의 0번째 차원과 1번째 차원을 교환(전치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6396153",
   "metadata": {},
   "outputs": [],
   "source": [
    "t23 = torch.t(t19)  # t는 transpose의 약어로 같은 기능을 한다.\n",
    "print(t23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915b189",
   "metadata": {},
   "source": [
    "# l_tensor_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904bb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat : 여러 개의 텐서를 주어진 차원에 맞춰 하나로 연결(concatenate)해줌\n",
    "t4 = torch.cat([t1, t2, t3], dim=1)\n",
    "#print(t4)\n",
    "print(t4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5c195",
   "metadata": {},
   "source": [
    "##### torch.cat([t1, t2, t3], dim=1) \n",
    "- t1, t2, t3: 연결하려는 원본 텐서들을 리스트로 제공함\n",
    "- dim=1: 연결할 때 차원 1(두 번째 차원)을 따라 연결하도록 지정함\n",
    "\n",
    "- 차원 1이 1,3,2 이므로 cat 하였을 때 6이 되고, 결과적으로 t4의 shape은 (2,6,3)이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a084859",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t6 = torch.arange(3, 8)  # tensor([3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d817ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = torch.cat((t5, t6), dim=0) # 인덱스0 차원(열)을 따라 연결\n",
    "print(t7.shape)  # torch.Size([8])\n",
    "print(t7)  # 0 차원을 따라 연결하므로 두 텐서의 원소가 순서대로 연결됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "t8 = torch.arange(0, 6).reshape(2, 3)  # [[0,1,2],[3,4,5]]\n",
    "t9 = torch.arange(6, 12).reshape(2, 3)  # [[6,7,8],[9,10,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fccb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 텐서간 병합\n",
    "t10 = torch.cat((t8, t9), dim=0) # 2차원 텐서를 인덱스0차원(행)에 따라 연결\n",
    "print(t10.size())  # torch.Size([4, 3])\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4291ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "t11 = torch.cat((t8, t9), dim=1) # 2차원 텐서를 인덱스1차원(열)에 따라 연결\n",
    "print(t11.size())  # torch.Size([2, 6])\n",
    "print(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t12 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t13 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t14 = torch.arange(12, 18).reshape(2, 3)  # torch.Size([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t15 = torch.cat((t12, t13, t14), dim=0) # 2차원 텐서 3개를 인덱스0차원(행)에 따라 연결\n",
    "print(t15.size())  # torch.Size([6, 3])\n",
    "print(t15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a019f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t16 = torch.cat((t12, t13, t14), dim=1) # 2차원 텐서 3개를 인덱스1차원(열)에 따라 연결\n",
    "print(t16.size())  # >>> torch.Size([2, 9])\n",
    "print(t16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3273f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)  # [[[0,1,2]],[3,4,5]]\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # [[[6,7,8]],[9,10,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d889f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t19 = torch.cat((t17, t18), dim=0) # 3차원 텐서 2개를 인덱스0차원(면)을 따라 연결\n",
    "print(t19.size())  # torch.Size([2, 2, 3])\n",
    "print(t19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t20 = torch.cat((t17, t18), dim=1) # 3차원 텐서 2개를 인덱스1 차원을 따라 연결\n",
    "print(t20.size())  # >>> torch.Size([1, 4, 3])\n",
    "print(t20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e860d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "t21 = torch.cat((t17, t18), dim=2) # 3차원 텐서 2개를 인덱스 2 차원을 따라 연결\n",
    "print(t21.size())  # >>> torch.Size([1, 2, 6])\n",
    "print(t21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681aef13",
   "metadata": {},
   "source": [
    "# m_tensor_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]]) # [2,3]\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]]) # [2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb15713",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.stack([t1, t2], dim=0) # (2,2,3)\n",
    "print(t3)\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0) # t1과 t2를 unsqueeze하여 3차원으로 만들고 cat. (2,2,3)\n",
    "print(t3.shape, t3.equal(t4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7f3ff",
   "metadata": {},
   "source": [
    "#### torch.stack(tensors, dim = 0)\n",
    "- 새로운 차원으로 확장하여 텐서 시퀀스를 병합\n",
    "--------\n",
    "\n",
    "\n",
    "- torch.stack([t1, t2], dim=0)는 t1과 t2를 0 차원(행)을 따라 수직으로 연결.\n",
    "- 두 텐서를 하나의 텐서로 쌓아 올리는 것을 의미\n",
    "- t3은 (2, 2, 3) 모양의 3차원 텐서가 됨\n",
    "<br>\n",
    "\n",
    "- torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0)는 t1과 t2를 0 차원(행)을 따라 연결하기 전에 unsqueeze() 함수를 사용하여 각각의 텐서를 차원을 확장하여 3차원으로 만듬\n",
    "- 그 다음 torch.cat() 함수를 사용하여 수직으로 연결\n",
    "- t4도 (2, 2, 3) 모양의 3차원 텐서가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.stack([t1, t2], dim=1) # ()\n",
    "#print(t5)\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1) # (2,1,3) (2,1,3) cat -> (2,2,3)\n",
    "print(t5.shape, t5.equal(t6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = torch.stack([t1, t2], dim=2)\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)\n",
    "print(t7.shape, t7.equal(t8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd62844",
   "metadata": {},
   "outputs": [],
   "source": [
    "t9 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t10 = torch.arange(3, 6)  # tensor([3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "t11 = torch.stack((t9, t10), dim=0)\n",
    "print(t11.size())  # torch.Size([2,3])\n",
    "print(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0)\n",
    "print(t11.equal(t12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "t13 = torch.stack((t9, t10), dim=1)\n",
    "print(t13.size())  # >>> torch.Size([3,2])\n",
    "print(t13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)\n",
    "print(t13.equal(t14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae64ad3",
   "metadata": {},
   "source": [
    "# n_tensor_vstack_hstack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7210de",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = torch.vstack((t1, t2)) # \"vertical stack\"의 줄임말\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb46d0",
   "metadata": {},
   "source": [
    "- 텐서들을 수직(세로) 방향으로 쌓아서(concatenate) 새로운 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ee719",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = torch.tensor([[1], [2], [3]])\n",
    "t5 = torch.tensor([[4], [5], [6]])\n",
    "t6 = torch.vstack((t4, t5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "t8 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bab770",
   "metadata": {},
   "outputs": [],
   "source": [
    "t9 = torch.vstack([t7, t8])\n",
    "print(t9.shape)\n",
    "print(t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t10 = torch.tensor([1, 2, 3])\n",
    "t11 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.hstack((t10, t11))\n",
    "print(t12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t13 = torch.tensor([[1], [2], [3]])\n",
    "t14 = torch.tensor([[4], [5], [6]])\n",
    "t15 = torch.hstack((t13, t14))\n",
    "print(t15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t16 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t17 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "t18 = torch.hstack([t16, t17])\n",
    "print(t18.shape)\n",
    "print(t18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97136beb",
   "metadata": {},
   "source": [
    "# 학습후기\n",
    "\n",
    "우선 이 과제를 하면서 Pytorch에서 사용되는 함수와 메서드를 글로 익히는 것 보다 더 수월하게 익힐 수 있었습니다.\n",
    "<br>\n",
    "\n",
    "특히 처음봤을때 머리로는 이해가 안되는 stack 같으 경우는 펜으로 직접 그림을 그려보며 익히기도 하며 코드로의 차원의 표현과 차원들끼리의 연산에 대해서 숙지하게 되었습니다.\n",
    "<br>\n",
    "\n",
    "강의 자료가 영어로 되어있어 하나하나 번역하여 공부하는 것이 힘들긴 했지만 담겨 있는 내용들이 핵심 내용들이고 제일 중요한 잘못된 정보가 없기 때문에 공부에만 집중할 수 있었습니다.  \n",
    "<br>\n",
    "\n",
    "파이썬을 접하기 시작하면서 항상 애매하게 헷갈려했던 부분이 인덱싱과 슬라이싱 부분이었는데 이번 계기로 잘 숙지할 수 있었고, 또 헷갈릴 때 언제든 제가 만든 이 파일로 공부를 할 수 있게 되었습니다. 인덱싱과 슬라이싱 부분이 중요하게 생각되어 후기 부분에 약간의 정리를 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736153ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9],\n",
    "   [10, 11, 12, 13, 14]]\n",
    ")\n",
    "\n",
    "print(x[:, 1]) # 모든 행에 대해서 1 번째 열 값\n",
    "print(x[1, 2]) # 1 번째 행의 2 번째 열 값\n",
    "print(x[0:2, -1]) # 0부터 1 번째 행에 대하여 마지막 열 값 \n",
    "print(x[1:, 3:]) # 1부터의 마지막까지의 행에 대하여 3부터 마지막 까지의 열 값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
