{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdbc4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from _99_common_utils.utils import strfdelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a1b0a",
   "metadata": {},
   "source": [
    "## Train Loss와 Validation Loss\n",
    "\n",
    "#### Train Loss\n",
    "* Train Loss (훈련 손실): 모델이 훈련 데이터를 학습할 때 발생하는 오차를 나타냅니다.\n",
    "* 모델이 훈련 데이터에 얼마나 적합한지를 나타내는 지표이며, 이 손실이 낮을수록 모델은 훈련 데이터에 더 적합합니다.\n",
    "\n",
    "#### Validation Loss\n",
    "* Validation Loss (검증 손실): 모델이 훈련 데이터 이외의 데이터에서 얼마나 잘 일반화되는지를 나타냅니다.\n",
    "* 일반화 능력은 모델의 실제 성능을 평가하는 데 중요한 역할을 합니다. \n",
    "* 검증 손실은 모델이 검증 데이터 (훈련 중에 사용하지 않은 데이터)에서 얼마나 잘 수행되는지를 측정하는 데 사용됩니다.\n",
    "\n",
    "---\n",
    "### 모델 훈련 목표 \n",
    "* 훈련 손실을 낮추는 것과 동시에 검증 손실을 최소화하는 것 \n",
    "* 이렇게 함으로써 모델은 훈련 데이터에 적합하면서도 일반화 능력을 향상시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6b4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "  \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "  def __init__(self, patience=10, delta=0.0001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
    "    self.patience = patience\n",
    "    self.counter = 0\n",
    "    self.delta = delta\n",
    "\n",
    "    self.val_loss_min = None\n",
    "    self.file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
    "    )\n",
    "    self.latest_file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6f3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def check_and_save(self, new_validation_loss, model):\n",
    "    early_stop = False\n",
    "\n",
    "    if self.val_loss_min is None:\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      message = f'Early stopping is stated!'\n",
    "    elif new_validation_loss < self.val_loss_min - self.delta:\n",
    "      message = f'V_loss decreased ({self.val_loss_min:6.3f} --> {new_validation_loss:6.3f}). Saving model...'\n",
    "      self.save_checkpoint(new_validation_loss, model)\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      self.counter = 0\n",
    "    else:\n",
    "      self.counter += 1\n",
    "      message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
    "      if self.counter >= self.patience:\n",
    "        early_stop = True\n",
    "        message += \" *** TRAIN EARLY STOPPED! ***\"\n",
    "\n",
    "    return message, early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f8390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def save_checkpoint(self, val_loss, model):\n",
    "    '''Saves model when validation loss decrease.'''\n",
    "    torch.save(model.state_dict(), self.file_path)\n",
    "    torch.save(model.state_dict(), self.latest_file_path)\n",
    "    self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e7aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTrainer:\n",
    "  def __init__(\n",
    "      # checkpoint_file_path(모델이 save 되는 위치)\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "  ):\n",
    "    self.project_name = project_name\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.train_data_loader = train_data_loader\n",
    "    self.validation_data_loader = validation_data_loader\n",
    "    self.transforms = transforms\n",
    "    self.run_time_str = run_time_str\n",
    "    self.wandb = wandb\n",
    "    self.device = device\n",
    "    self.checkpoint_file_path = checkpoint_file_path\n",
    "\n",
    "    # Use a built-in loss function\n",
    "    self.loss_fn = nn.CrossEntropyLoss() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcf6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def do_train(self):\n",
    "    self.model.train()  # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_train = 0.0\n",
    "    num_corrects_train = 0\n",
    "    num_trained_samples = 0\n",
    "    num_trains = 0\n",
    "\n",
    "    for train_batch in self.train_data_loader:\n",
    "      input_train, target_train = train_batch\n",
    "      input_train = input_train.to(device=self.device)\n",
    "      target_train = target_train.to(device=self.device)\n",
    "\n",
    "      input_train = self.transforms(input_train)\n",
    "\n",
    "      output_train = self.model(input_train)\n",
    "      loss = self.loss_fn(output_train, target_train)\n",
    "      loss_train += loss.item()\n",
    "\n",
    "      predicted_train = torch.argmax(output_train, dim=1)\n",
    "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "      num_trained_samples += len(input_train)\n",
    "      num_trains += 1\n",
    "\n",
    "      ##\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      ##\n",
    "\n",
    "    train_loss = loss_train / num_trains\n",
    "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832d50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def do_validation(self):\n",
    "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_corrects_validation = 0\n",
    "    num_validated_samples = 0\n",
    "    num_validations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in self.validation_data_loader:\n",
    "        input_validation, target_validation = validation_batch\n",
    "        input_validation = input_validation.to(device=self.device)\n",
    "        target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "        input_validation = self.transforms(input_validation)\n",
    "\n",
    "        output_validation = self.model(input_validation)\n",
    "        loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
    "\n",
    "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "        num_validated_samples += len(input_validation)\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3f46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def train_loop(self): # do_train과 do_validation을 호출함 #for루프를 돌리면서 조건이 만족되면 do_validation 호출 \n",
    "    early_stopping = EarlyStopping(\n",
    "      patience=self.wandb.config.early_stop_patience,\n",
    "      project_name=self.project_name,\n",
    "      checkpoint_file_path=self.checkpoint_file_path,\n",
    "      run_time_str=self.run_time_str\n",
    "    )\n",
    "    n_epochs = self.wandb.config.epochs\n",
    "    \n",
    "    ##\n",
    "    training_start_time = datetime.now()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      train_loss, train_accuracy = self.do_train() #do_train#\n",
    "\n",
    "      if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "        validation_loss, validation_accuracy = self.do_validation() #do_validation#\n",
    "\n",
    "        # eplapsed: 지나간, 경과된\n",
    "        elapsed_time = datetime.now() - training_start_time #\n",
    "        epoch_per_second = epoch / elapsed_time.seconds # elapsed_time.second: 경과된 시간을 초(s)로 반환\n",
    "\n",
    "        # check_and_save -> validation loss의 더 작은 값을 찾았을 때마다\n",
    "        message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "\n",
    "        print(\n",
    "          f\"[Epoch {epoch:>3}] \"\n",
    "          f\"T_loss: {train_loss:6.4f}, \"\n",
    "          f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "          f\"V_loss: {validation_loss:6.4f}, \"\n",
    "          f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "          f\"{message} | \"\n",
    "          f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "          f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "        )\n",
    "\n",
    "        self.wandb.log({\n",
    "          \"Epoch\": epoch,\n",
    "          \"Training loss\": train_loss,\n",
    "          \"Training accuracy (%)\": train_accuracy,\n",
    "          \"Validation loss\": validation_loss,\n",
    "          \"Validation accuracy (%)\": validation_accuracy,\n",
    "          \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "        })\n",
    "\n",
    "        if early_stop:\n",
    "          break\n",
    "\n",
    "    elapsed_time = datetime.now() - training_start_time\n",
    "    print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
